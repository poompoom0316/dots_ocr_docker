# use cuda 12.8

docker run -it --rm --gpus all \
  --entrypoint /bin/bash \
  -e NVIDIA_DISABLE_REQUIRE=true \
  -e CUDA_VISIBLE_DEVICES=0 \
  -p 8000:8000 \
  dotsocr-vllm:latest

CUDA_VISIBLE_DEVICES=0 vllm serve ${hf_model_path} --tensor-parallel-size 1 --gpu-memory-utilization 0.75 --chat-template-content-format string --served-model-name model --trust-remote-code --max-model-len=32768
